## ClassDef ConversationCallbackHandler
**ConversationCallbackHandler**: The function of the ConversationCallbackHandler class is to handle callbacks during the conversation, specifically to update the message content after a response has been generated using a large language model (LLM). 

**Properties**:
- `conversation_id`: A string type that represents a unique identifier for a conversation.
- `message_id`: A string type that represents a unique identifier for a message.
- `chat_type`: String type, which indicates the type of chat.
- `query`: A string type that represents a user's query or input.
- `start_at`: Initialized as None, which can be used to record the start time of certain operations.
- `raise_error`: Boolean type, which is True by default, indicates whether an exception is thrown when an error is encountered during processing.

**Code Description**:
ConversationCallbackHandler inherits from BaseCallbackHandler and is a class specifically designed to handle callback logic in chat applications. It is initialized by receiving parameters such as Conversation ID, Message ID, Chat Type, and User Query. There is a property defined in this class`always_verbose` that always returns True, meaning that the verbose callback function will be called regardless of how the verbose parameter is set. In addition, it contains two methods`on_llm_start` `on_llm_end`sum, which are called when the large language model (LLM) starts processing and ends processing, respectively. `on_llm_end`method, it extracts the generated text from the LLM's response and calls a`update_message` function to update the message content. 

In the project, the ConversationCallbackHandler was used `server/chat/chat.py/chat/chat_iterator`to process and update responses generated when using a large language model for a chat. In the conversation iterator, an instance of ConversationCallbackHandler is created and added to the callback list. In this way, whenever the LLM processing is complete, the`on_llm_end` corresponding message content is updated by the method. 

**Note**:
- When using the ConversationCallbackHandler, you need to make sure that`conversation_id` the ,`message_id` and the `chat_type`parameters provided are `query`correct, as this information will be used for critical aspects of message updates and callback processing. 
- `on_llm_start`The method is currently blank, but can be extended as needed to store more information related to LLM processing.

**Example output**:
Since the ConversationCallbackHandler is primarily responsible for callback handling and does not directly produce output, there is no specific output example. However, the content of a message may be updated from the user's original query to the response text generated by the LLM. 
### FunctionDef __init__(self, conversation_id, message_id, chat_type, query)
**__init__**: The function of the __init__ function is to initialize an instance of the ConversationCallbackHandler class. 

**Parameters**:
- conversation_id: Session ID, which identifies a specific conversation.
- message_id: The message ID, which identifies a specific message in the conversation.
- chat_type: The type of chat, which describes the nature of the chat (e.g., private chat, group chat, etc.).
- query: A query string that is used to process or respond to a specific query request.

**Code Description**:
This __init__ function is the constructor of the ConversationCallbackHandler class and is used to initialize the properties of an instance of the class when it is created. In this function, four parameters are received: conversation_id, message_id, chat_type, and query, which are used to initialize the corresponding properties of the instance. In addition, there is a property start_at, which is initialized as Zero in this function, which may be used to record the time of session start or other time-related information, but the specific purpose depends on how the rest of the class or method uses it. 

**Note**:
- When you create an instance using the ConversationCallbackHandler class, you must provide four parameters: conversation_id, message_id, chat_type, and query, which are essential to the functionality of the instance.
- start_at property is initialized without a specific value (set to None), which means that if you want to use this property, you should set it appropriately in other methods of the class.
- This constructor does not return any value and is only used to initialize the state of the instance.
***
### FunctionDef always_verbose(self)
**always_verbose**: The function of this function is to decide whether to call the verbose callback when verbose mode is False. 

****Arguments: This function has no arguments. 

**Code Description**:  A `always_verbose` function is `ConversationCallbackHandler` a method of the class designed to control the behavior of the callback handler. Specifically, it indicates whether the callback handler should always be in verbose mode when handling callbacks, even if verbose mode is not enabled in the global settings. This method achieves this behavior by returning a boolean value `True` , indicating that the verbose callback should be called regardless of the global verbose setting. This is useful for developers in debugging or scenarios where detailed log information is required, as it allows a separate callback handler to ignore the global verbose settings and always run in verbose mode. 

**Note**: When using this feature, developers should be aware that even if the global verbose is set to False, the `always_verbose` callback handler with the method enabled will still produce verbose log output. This can result in a significant increase in the amount of log information, so it is recommended only for debugging or when detailed logs are specifically required. 

**Example output**: Since `always_verbose` the method returns a Boolean value `True`, when this method is called, its output example will simply be:

```python
True
```
***
### FunctionDef on_llm_start(self, serialized, prompts)
**on_llm_start**: This function is used to handle the logic related to the start of a large language model (LLM) session. 

**Parameters**:
- `serialized`: A dictionary-type parameter containing information that needs to be serialized. The key-value pair is of type`str` to`Any`, i.e. the key is a string type, and the value can be of any type. 
- `prompts`: A list of strings that contains prompts when starting a large language model session.
- `**kwargs`: Receive any additional keyword parameters. The types of these parameters are not fixed and can be passed to the function as needed.

**Code Description**:
`on_llm_start`The primary role of a function is to perform the necessary logical processing at the beginning of a large language model (LLM) session. This includes, but is not limited to, initializing the session, setting session parameters, recording session information, etc. The function receives two main arguments:`serialized` and`prompts`. `serialized`A parameter is a dictionary that passes information that needs to be serialized, which may include the configuration of the session, the identity of the user, and so on. `prompts`A parameter is a list of strings that provides a hint when starting a session, which may be used to guide the language model to generate a response. In addition, the function can also receive any number of keyword arguments (),`**kwargs` which provides a high degree of flexibility for the function, allowing more functionality or processing logic to be added without modifying the function signature. 

**Note**:
- When actually using `on_llm_start`functions, developers need to pay attention to the`serialized` `prompts`content and format of parameters to ensure that they meet the requirements of large language model processing. 
- The comment in the function says "prompts need to be persisted if you want to store more information", which means that if additional information needs to be recorded during the session, then the developer should consider adding this information`prompts` to the session and making sure that it can be serialized and stored appropriately. 
- Since the current implementation of the function is empty(`pass`), developers need to complete the logical implementation according to their specific needs when integrating it into the project. 
***
### FunctionDef on_llm_end(self, response)
**on_llm_end**: The function of this function is to update the content of the replies in the chat history after the language model has finished processing. 

**Parameters**:
- `response`: LLMResult type, which contains the results generated by the language model.
- `**kwargs`: Accepts any number of keyword arguments for extra flexibility.

**Code Description**:
`on_llm_end`The method first `response`extracts the first reply text generated by the language model from the object. This text was obtained by`response.generations[0][0].text` visiting, which `generations`is a nested list of all generated responses. Then, the method calls `update_message`a function to update the extracted reply text to the corresponding chat history in the database. At the`update_message` time of calling, the parameters passed in include`self.message_id` and extract the reply text`answer`. `self.message_id`It is the unique identification ID of the chat history that needs to be updated, and it`answer` is the new reply content. 

`update_message`A function is a function defined in `server/db/repository/message_repository.py`, and its main function is to update the chat history that is already in the database. It works by `message_id`targeting a specific chat history and updating it based on the content or metadata of the new reply provided. In the`on_llm_end` method, `update_message`the call implements the timely update of the generated reply to the database after the language model has been processed, ensuring that the chat history remains up-to-date. 

**Note**:
- Make sure that `response`the parameter is a valid LLMResult object and contains at least one generated reply to avoid errors when accessing non-existent indexes. 
- In practice, you need to make sure that the `self.message_id`corresponding chat record exists in the database so that `update_message`the function can find and update the record correctly. 
- `**kwargs`Parameters provide additional flexibility, but are not used directly in current implementations. Developers can extend the functionality of the method in future versions as needed, taking advantage of these additional parameters.
***
