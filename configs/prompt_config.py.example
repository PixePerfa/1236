# The prompt template uses Jinja2 syntax, which is simply to use double curly braces instead of single curly braces for f-string
# This configuration file supports hot loading, and there is no need to restart the service after modifying the prompt template.

# Variables supported by LLM dialogs:
# - input: User input

# Variables supported by knowledge base and search engine conversations:
# - context: Knowledge text stitched together from search results
# - question: A question raised by a user

# Variables supported by agent dialogs:

# - tools: A list of available tools
# - tool_names: List of available tool names
# - history: The history of conversations between the user and the agent
# - input: User input
# - agent_scratchpad: Agent's thought record

PROMPT_TEMPLATES = {
    "llm_chat": {
        "default":
            '{{ input }}',

        "with_history":
            'The following is a friendly conversation between a human and an AI. '
            'The AI is talkative and provides lots of specific details from its context. '
            'If the AI does not know the answer to a question, it truthfully says it does not know.\n\n'
            'Current conversation:\n'
            '{history}\n'
            'Human: {input}\n'
            'AI:',

        "py":
            'You're a clever code helper, please write me simple py code. \n'
            '{{ input }}',
    },


    "knowledge_base_chat": {
        "default":
            < instructions > answer questions based on what you know, concisely and professionally. If you can't get an answer from it, say 'Cannot answer the question based on what is known,'
            'It is not allowed to add components to the answer, please use Chinese for the answer. </Commands>\n'
            '< known information>{{ context }}</known information>\n'
            '< Question>{{ question }}</Question>\n',

        "text":
            < instructions > answer questions based on what you know, concisely and professionally. If you can't get an answer from it, say "Cannot answer this question based on known information" in Chinese. </Commands>\n'
            '< known information>{{ context }}</known information>\n'
            '< Question>{{ question }}</Question>\n',

        "empty": # Used when the knowledge base cannot be found
            'Could you please answer my question:\n'
            '{{ question }}\n\n',
    },


    "search_engine_chat": {
        "default":
            < instructions> This is the Internet information I searched, please extract it according to this information and answer the question concisely. '
            If you can't get an answer from it, say "Unable to search for content that answers the question." </Commands>\n'
            '< known information>{{ context }}</known information>\n'
            '< Question>{{ question }}</Question>\n',

        "search":
            < instructions > answer questions based on what you know, concisely and professionally. If you can't get an answer from it, say "Cannot answer this question based on known information" in Chinese. </Commands>\n'
            '< known information>{{ context }}</known information>\n'
            '< Question>{{ question }}</Question>\n',
    },


    "agent_chat": {
        "default":
            'Answer the following questions as best you can. If it is in order, you can use some tools appropriately. '
            'You have access to the following tools:\n\n'
            '{tools}\n\n'
            'Use the following format:\n'
            'Question: the input question you must answer1\n'
            'Thought: you should always think about what to do and what tools to use.\n'
            'Action: the action to take, should be one of [{tool_names}]\n'
            'Action Input: the input to the action\n'
            'Observation: the result of the action\n'
            '... (this Thought/Action/Action Input/Observation can be repeated zero or more times)\n'
            'Thought: I now know the final answer\n'
            'Final Answer: the final answer to the original input question\n'
            'Begin!\n\n'
            'history: {history}\n\n'
            'Question: {input}\n\n'
            'Thought: {agent_scratchpad}\n',

        "ChatGLM3":
            'You can answer using the tools, or answer directly using your knowledge without using the tools. '
            'Respond to the human as helpfully and accurately as possible.\n'
            'You have access to the following tools:\n'
            '{tools}\n'
            'Use a json blob to specify a tool by providing an action key (tool name) '
            'and an action_input key (tool input).\n'
            'Valid "action" values: "Final Answer" or  [{tool_names}]'
            'Provide only ONE action per $JSON_BLOB, as shown:\n\n'
            '```\n'
            '{{{{\n'
            '  "action": $TOOL_NAME,\n'
            '  "action_input": $INPUT\n'
            '}}}}\n'
            '```\n\n'
            'Follow this format:\n\n'
            'Question: input question to answer\n'
            'Thought: consider previous and subsequent steps\n'
            'Action:\n'
            '```\n'
            '$JSON_BLOB\n'
            '```\n'
            'Observation: action result\n'
            '... (repeat Thought/Action/Observation N times)\n'
            'Thought: I know what to respond\n'
            'Action:\n'
            '```\n'
            '{{{{\n'
            '  "action": "Final Answer",\n'
            '  "action_input": "Final response to human"\n'
            '}}}}\n'
            'Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. '
            'Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\n'
            'history: {history}\n\n'
            'Question: {input}\n\n'
            'Thought: {agent_scratchpad}',
    }
}
