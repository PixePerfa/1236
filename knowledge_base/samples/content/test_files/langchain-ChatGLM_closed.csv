,title,file,url,detail,id
0,Come on~ as well as some advice,2023-03-31.0002,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/2,"Come on, I think you're heading in the right direction.",0
1,"What is the current operating environment, Windows or Linux",2023-04-01.0003,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/3,"What is the current operating environment, windows or Linux, and what version is python?",1
2,Is this running on top of CLM?,2023-04-01.0004,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/4,"Do I need to install CLM locally and run it normally, and then follow the steps in this article to run it?",2
3,[Reproducing Issue] Text garbled extracted from the knowledge base when constructing a prompt,2023-04-01.0005,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/5,"Hi, I was trying to reproduce the effect in the README, and I also used the README of ChatGLM-6B as the input text, but I found that the text extracted from the knowledge base was garbled, resulting in the constructed prompt not being available. Want to know how to fix this.",3
4,Can contextual conversations be added later?,2023-04-02.0006,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/6,"At present, the function of historical message passing has been implemented in the get_wiki_agent_answer function, and I will confirm whether the chat_history is passed during the model call in langchain.",4
5,Excuse me: Is pure CPU OK?,2023-04-03.0007,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/7,Cool implementation that has greatly broadened my horizons! It ran smoothly on the GPU machine,5
6,Error: 'NoneType' object has no attribute 'message_types_by_name',2023-04-03.0008,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/8,Error:,6
7,Operating Environment: How big does the GPU need to be?,2023-04-03.0009,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/9,"If you follow THUDM/ChatGLM-6B, the size of the GPU used should be around 13GB, but after running the script, 24GB is not enough.",7
8,What is the format of local knowledge?,2023-04-03.0010,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/10,"The tested format includes text information in docx and md files, please refer to [langchain documentation](https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/unstructured_file.html?highlight=pdf#) for specific formats.",8
9,"24G video memory is still blown up, whether it supports dual SIM operation",2023-04-03.0011,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/11,RuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 23.70 GiB total capacity; 22.18 GiB already allocated; 12.75 MiB free; 22.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,9
10,How do you know that the embeddings are the same as the model training?,2023-04-03.0012,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/12,"The methods of embedding and LLM do not need to be the same, embedding can solve the needs of semantic retrieval. The embedding used in this project is the process of indexing local knowledge and converting questions into vectors.",10
11,Is it possible to provide the format of local knowledge files?,2023-04-04.0013,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/13,Is it possible to provide the format of local knowledge files?,11
12,Is it possible to run a card below 8G like the original Tsinghua version?,2023-04-04.0016,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/16,Is it possible to run a card below 8G like the original Tsinghua version? My 8G card exploded 🤣🤣🤣,12
13,Tell me how Langchain coordinates the use of vector libraries and chatGLM,2023-04-05.0018,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/18,"This paragraph in the code is to create a question and answer model, which will be connected to ChatGLM and the vector library of the local corpus. Search the vector library first, didn't find chatglm again? Or what mechanism?",13
14,The ValueError: 150001 is not in list exception is thrown on mac m2max,2023-04-05.0019,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/19,I've changed the code chatglm_llm.py load the model to look like this,14
15,The program keeps getting stuck after it runs,2023-04-05.0020,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/20,"Thanks to the author for his efforts, but I have a problem with the runtime, please help.",15
16,Ask about the logic of chat_history,2023-04-06.0022,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/22,Thanks for open source.,16
17,Why is the checkpoint being loaded every time it runs,2023-04-06.0023,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/23,"After I downloaded this embedding model to my local computer, it didn't start properly.",17
18,Can I upload some examples of local knowledge files?,2023-04-06.0025,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/25,"As the question, how to construct a knowledge file to achieve a better effect? Can you provide a sample?",18
19,What version of you are using?,2023-04-06.0026,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/26,"Hi Panda, I saw the `pip install -r requirements` command in README, and want to confirm you are using python2 or python3? because my pip and pip3 version are all is 22.3.",19
20,Friends who are interested in communicating the application of this project can add a WeChat group,2023-04-07.0027,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/27,! [IMG_1630] (https://user-images.githubusercontent.com/5668498/230533162-8b9bfcdd-249c-4efe-b066-4f9ba2ce9f23.jpeg),20
21,"The more local knowledge you have, the longer it will take to retrieve your answers",2023-04-07.0029,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/29,Yes because a vector matching retrieval is required,21
22,Why did you end up crying with an error?。。,2023-04-07.0030,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/30,Failed to import transformers.models.t5.configuration_t5 because of the following error (look up to see,22
23,"The second time we talk, we get an error like UnicodeDecodeError: 'utf-8' codec can't decode",2023-04-07.0031,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/31,"The first time the conversation is no problem, after the model returns the output, it gives you your question, and I enter the question again",23
24,The quantized version of in4 is used to apply for 10Gb of video memory when reasoning,2023-04-07.0033,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/33,"File "/root/.cache/huggingface/modules/transformers_modules/chatglm-6b-int4-qe/modeling_chatglm.py", line 581, in forward",24
25,"Running with colab, python3.9, it says that there is a problem with package import",2023-04-07.0034,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/34,"from ._util import is_directory, is_path",25
26,"The operation failed, and the loading checkpoint was not killed before reaching 100%, what is the reason?",2023-04-07.0035,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/35,The logs are as follows:,26
27,"I made a communication group.,I can't figure out a lot of details by myself.,Let's discuss technology plus connection-image I'll pull you.",2023-04-08.0036,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/36,"I don't know how much I don't know about it.,Let's get it together.。。 Prepare to make a deployment problem solving document out",27
28,Error using the new version with langchain,2023-04-09.0043,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/43,Error with the new changes:,28
29,How Do I Fix the Error Reported in the Program at torch.cuda.OutOfMemoryError?,2023-04-10.0044,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/44,The following details are displayed:,29
30,How is the training data format for QA set,2023-04-10.0045,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/45,"This project is not a fine-tuning method, so it does not involve the training process.",30
31,The FileType.UNK file type is not supported in partition. Solution,2023-04-10.0046,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/46,ValueError: Invalid file /home/yawu/Documents/langchain-ChatGLM-master/data. The FileType.UNK file type is not supported in partition.,31
32,How do I read multiple txt documents?,2023-04-10.0047,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/47,"As questioned, how do I read multiple txt documents? In the example code, there is only a case of reading one document, and I can only specify one document after I replace this input with string, and I can't specify multiple documents with wildcards, and I can't pass in a list of multiple file paths.",32
33,nltk package unable to either download or load local nltk_data folder,2023-04-10.0049,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/49,I'm running this project on an offline Windows Server environment so I download the Punkt and averaged_perceptron_tagger tokenizer in this directory:,33
34,The langchain version needs to be specified in the requirements.txt,2023-04-11.0055,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/55,"RetrievalQA cannot be introduced under langchain version 0.116, you need to specify a higher version (no problem under version 0.136)",34
35,The demo cannot give the output content,2023-04-12.0059,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/59,"Hello, I tested the project's own press release sample and a text uploaded by myself, which can be loaded, but can't give an answer, what is the situation, how to solve it, thank you. PS: 1. I just downloaded all the codes this morning; 2. The hardware server meets the requirements; 3. Operate normally according to the operating instructions.",35
36,"There are too many people in the group to join the group, so ask for help to pull into the group",2023-04-12.0061,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/61,"Hello, the number of people in your group exceeds 200, and it is currently impossible to join the group through the QR code, can you easily add me to WeChat and pull me into the group? Thank you very much",36
37,"The group is full, and beg the big guy to join the group",2023-04-12.0062,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/62,The QR code has been updated in the README,37
38,The langchain version in Requirements is incorrect,2023-04-12.0065,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/65,The langchain version should be 0.0.12 instead of 0.0.120,38
39,Linux : Searchd in,2023-04-13.0068,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/68,import nltk,39
40,No sentence-transformers model found,2023-04-13.0069,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/69,"The model cannot be loaded, and the error is that the model cannot be found, but the path is configured",40
41,Error loading punkt: <urlopen error [Errno 111] Connection,2023-04-13.0070,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/70,"knowledge_based_chatglm.py running, an NLTK error is displayed, as follows:",41
42,"[don't understand, just ask] ptuning dataset format",2023-04-13.0072,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/72,"Hello everyone, is there any mystery in fine-tuning the format of the dataset? I see ChatGLM-6B/ptuning/readme.md, why is the content in the demo dataset ADGEN written as Type#skirt*style#simplicity This format? What's the mystery here? I hereby ask for advice",42
43,Embedding model,2023-04-13.0074,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/74,"Hello, I see that the embedding model in the project uses: GanymedeNil/text2vec-large-Chinese, can the embedding model in this project directly use ChatGLM?",43
44,"Macbook M1 is running webui.py and an error message is being reported, please ask if it can support M-series chips",2023-04-13.0080,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/80,```,44
45,new feature: Added support for P-tunningv2 fine-tuned models,2023-04-14.0099,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/99,Is it possible to add a new feature to provide loading support for models after fine-tuning chatglm using [P-tunningv2] (https://github.com/THUDM/ChatGLM-6B/tree/main/ptuning).,45
46,"The txt file is loaded successfully, but an error is reported when it is read",2023-04-15.0106,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/106,"The latest version of the code. What's weird is that my computer doesn't have a D disk.,How can there be a D disk out of the error message...",46
47,The model was loaded successfully? The file cannot be imported.,2023-04-15.0107,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/107,All models are local.,47
48,What operating system do you use?,2023-04-16.0110,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/110,"Ubuntu, CentOS or Windows?",48
49,Error message ModuleNotFoundError: No module named 'configs.model_config',2023-04-17.0112,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/112,"After updating the code, run webui.py and get the error ModuleNotFoundError: No module named 'configs.model_config'. No workaround found.",49
50,Asking specific questions will explode the video memory,2023-04-17.0116,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/116,It's okay to ask questions normally.,50
51,Loading can't get in?,2023-04-18.0127,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/127,"After opening the web page after python webui.py on the Linux system, it has been loading, is it related to the fact that I didn't install detectron2?",51
52,What is the limit to the amount of local knowledge content?,2023-04-18.0129,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/129,"The local knowledge file type is txt, and if there are more than 5 pieces of data, it will explode when you ask a question.",52
53,"I had planned to make a similar product, and it didn't seem like I had to start from scratch",2023-04-18.0130,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/130,Is there room for optimization in text cutting? WeChat groups can no longer be added.,53
54,load model failed. Failed to load the model,2023-04-18.0132,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/132,```,54
55,How do I return the referenced local data content when answering in the webui?,2023-04-18.0133,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/133,Title,55
56,"I can't add more than 200 people to the exchange group, can you give me the contact information of the person in charge to pull me into the group?",2023-04-20.0143,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/143,Together,56
57,"No sentence-transformers model found with name '/text2vec/', but there is indeed a model file underneath the path",2023-04-20.0145,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/145,Also: The dtype of attention mask (torch.int64) is not bool,57
58,"Where is the path to load the model modified, it seems that the default will be preceded by transformers_modules.",2023-04-20.0148,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/148,<img width="1181" alt="1681977897052" src="https://user-images.githubusercontent.com/30926001/233301106-3846680a-d842-41d2-874e-5b6514d732c4.png">,58
59,"Why does it get an error when I put it in a method call, and how to deal with this?",2023-04-20.0150,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/150,```python,59
60,No sentence-transformers model found with name C:\Users\Administrator/.cache\torch\sentence_transformers\GanymedeNil_text2vec-large-chinese. Creating a new one with MEAN pooling.,2023-04-21.0154,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/154,Is it normal to be stuck in this piece for a long time?,60
61,WeChat groups require an invitation to join,2023-04-21.0155,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/155,"RT, give a personal contact information white",61
62,No sentence-transformers model found with name GanymedeNil/text2vec-large-chinese. Creating a new one with MEAN pooling,2023-04-21.0156,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/156,ls GanymedeNil/text2vec-large-Chinese,62
63,embedding is loaded twice,2023-04-23.0159,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/159,"Hello, why do you want to set it up like this, it will load twice.",63
64,"Scan the QR code to add the group, the group members are full and can't enter",2023-04-23.0160,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/160,Title,64
65,Executing python3 cli_demo.py Error Message: 'NoneType' object has no attribute 'chat',2023-04-24.0163,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/163,"At first, I suspected that it was a memory shortage problem, and if I changed it to int4, int4-qe would not work, did anyone know what the reason was",65
66,Match score,2023-04-24.0167,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/167,"The matching text returned in the example cli_demo.py does not have a corresponding score, can I add this feature?",66
67,Does the big guy have any plans to add a typewriter function to the web_ui.py?,2023-04-25.0170,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/170,"At present, after loading the knowledge base, a single V100 32G also needs more than 20S to answer questions in the vertical field, and the use of word-for-word output without a typewriter is still more painful....",67
68,Is it possible to use a verctorDB for the embedings?,2023-04-25.0171,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/171,"when I play, I have to load the local data again and again when to start. I wonder if it is possible to use",68
69,How do I load the fine-tuning model file obtained by LoRa training the official model?,2023-04-25.0173,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/173,The following documents are obtained by LoRa training:,69
70,From langchain.chains where is the code for import RetrievalQA?,2023-04-25.0174,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/174,local_doc_qa.py,70
71,Where are knowledge_based_chatglm.py documents? Why can't I find it?? Was it replaced with a cli_demo.py file?,2023-04-26.0175,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/175,Where are knowledge_based_chatglm.py documents? Why can't I find it?? Was it replaced with a cli_demo.py file?,71
72,AttributeError: 'Chatbot' object has no attribute 'value',2023-04-26.0177,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/177,Traceback (most recent call last):,72
73,The console api.py alert,2023-04-26.0178,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/178,you must pass the application as an import string to enable "reload" or "workers",73
74,How to join a group chat,2023-04-27.0183,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/183,"There are more than 200 people in the WeChat group, and I need to be invited, how to join?",74
75,How to combine Chatglm with local knowledge,2023-04-27.0185,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/185,"Hello, I would like to ask how to make the knowledge base match the text and chatglm generated combined, instead of saying that if it is not searched, it will not be able to answer the question based on the known information, thank you",75
76,A little advice,2023-04-27.0189,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/189,1.Weiui's get_vector_store method adds a judgment to be compatible with the upload exception caused by the gradio version,76
77,"In the Windows environment, follow the tutorial to configure the Conda environment, git the project, modify the model path, and run the demo with an error missing",2023-04-28.0194,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/194,The error code is as follows:,77
78,ValueError: too many values to unpack (expected 2),2023-04-28.0198,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/198,"When i tried to use the non-streaming, `ValueError: too many values to unpack (expected 2)` error came out.",78
79,"After loading the doc, the original knowledge is overwritten",2023-04-28.0201,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/201,"When a larger amount of private knowledge base is loaded, the original knowledge will be overwritten",79
80,Custom knowledge base answers are poor,2023-04-28.0203,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/203,"I added a custom knowledge base knowledge base, and the answer effect is very poor, is it because the amount of data is too small?",80
81,"Under python 310, the installation of pycocotools fails, and the lower version of cython is displayed, but the higher version is actually installed",2023-04-29.0208,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/208,"RT,Pure offline environment installation,It's very difficult to rely on installation,Finally, I encountered pycocotools,I can't install it,Ask for advice!",81
82,[FEATURE] Support RWKV model (pip package & rwkv.cpp etc.),2023-05-01.0216,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/216,"Hello, I am the author of RWKV, the introduction see: https://zhuanlan.zhihu.com/p/626083366",82
83,[BUG] Why can't the host/server start the service normally when it is not connected to the Internet?,2023-05-02.0220,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/220,**Problem Description**,83
84,[BUG] Concise description of the issue,2023-05-03.0222,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/222,**local variable 'torch' referenced before assignment**,84
85,Chinese input of txt files is not supported,2023-05-04.0235,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/235,"vs_path, _ = local_doc_qa.init_knowledge_vector_store(filepath)",85
86,"None of the files were loaded successfully, please check the dependencies or replace them with other files and upload them again. The file did not load successfully, please re-upload the file",2023-05-05.0237,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/237,"Please help the big guy solve it, thank you!",86
87,[BUG] chatglm model is loaded twice when using multi-card,2023-05-05.0241,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/241,chatglm_llm.py file loads the chatglm model once on line 129 and again on line 143,87
88,[BUG] Score result error when similarity_search_with_score_by_vector function returns multiple docs,2023-05-06.0252,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/252,**Problem Description**,88
89,"Can you create another communication group, this group is full and can't get in.",2023-05-06.0255,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/255,"It should have been updated in the readme in the morning.,If you can't add it, it may be a web cache problem.,You can try to scan img/qr_code_12.jpg directly.",89
90,Pls what is this error wow? KeyError: 'serialized_input',2023-05-06.0257,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/257,What is this error after running "python webui.py"? How to solve it?,90
91,Where can I modify the code and run it on the CPU?,2023-05-06.0258,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/258,**Problem Description**,91
92,ModuleNotFoundError: No module named 'modelscope',2023-05-07.0266,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/266,Install this,92
93,"When loading a LoRa fine-tuning model, the LoRa parameters are loaded successfully, but the model is not loaded successfully?",2023-05-08.0270,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/270,What is the reason?,93
94,[BUG] Running webui.py yields the error: name 'EMBEDDING_DEVICE' is not defined,2023-05-08.0274,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/274,"Solved, I changed this variable wrong when I modified model_config",94
95,"Based on the ptuning training, both the old and new models were loaded, but only the new ones",2023-05-08.0280,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/280,licitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.,95
96,"[BUG] When using chatyuan model, dialogue Error, has no attribute 'stream_chat'",2023-05-08.0282,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/282,**Problem Description**,96
97,There is a stop in the _call prompt during the chaglm call,2023-05-09.0286,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/286,**Feature Description**,97
98,Logger._log() got an unexpected keyword argument 'end',2023-05-10.0295,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/295,"When using cli_demo, load a common txt file, and after entering the problem, the error message is displayed: "TypeError: Logger._log() got an unexpected keyword argument 'end'"",98
99,[BUG] Can you explain the purpose of this FAISS.similarity_search_with_score_by_vector = similarity_search_with_score_by_vector?,2023-05-10.0296,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/296,"I don't quite understand what this library does with its own similarity_search_with_score_by_vector methods, because the original similarity_search_with_score_by_vector of langchain is just a combination of the returned topk sentences after search faiss. I don't think there's anything wrong with the original, but I didn't understand much about what else was done in this library, because there were no notes.",99
100,"[BUG] If you upload a Chinese file name file under Windows, faiss cannot generate a vector database file",2023-05-11.0318,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/318,**Problem Description**,100
101,Can the streaming output in the cli_demo follow up on the output of the previous answer?,2023-05-11.0320,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/320,The existing streaming output result style is:,101
102,"If the webpage cannot be loaded during intranet deployment, can offline static resources be added?",2023-05-12.0326,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/326,"If the webpage cannot be loaded during intranet deployment, can offline static resources be added?",102
103,"I want to change the encoding format of the file characters to encoding='utf-8', because there will be an ASCII codec can't decode byte error",2023-05-14.0360,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/360,"An error occurs when uploading a txt file in Chinese, and the encoding format is UTF-8",103
104,Where is the progress bar for Batches set? Can I turn off the display?,2023-05-15.0366,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/366,"When using cli_demo.py for command-line testing, each answer is preceded by a progress bar for Batches",104
105,ImportError: dlopen: cannot load any more object with static TLS or Segmentation fault,2023-05-15.0368,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/368,**Problem Description**,105
106,An error occurs when reading a PDF,2023-05-16.0373,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/373,"When performing a cli_demo.py on Colab, a pdf file is placed in the path folder, and an error is displayed during loading, and then the PDF file cannot be loaded",106
107,[BUG] The webui error message InvalidURL is reported,2023-05-16.0375,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/375,Python version: 3.8.16,107
108,[FEATURE] WHAT TO DO IF THE ANSWER DOES NOT CONTAIN THE SOURCE,2023-05-16.0380,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/380,**Feature Description**,108
109,"When loading a PDF file, I see unsupported colorspace for 'png'",2023-05-16.0381,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/381,**Problem Description**,109
110,'ascii' codec can't encode characters in position 14-44: ordinal not in range(128) classic bug,2023-05-16.0382,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/382,"This problem arises when you have a conversation after adding a knowledge base, and then you add a new knowledge base.",110
111,"The number of people in the WeChat group is more than 200, and I can't get in by scanning the code, can the group owner create a new group?",2023-05-17.0391,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/391,**Feature Description**,111
112,TypeError: 'ListDocsResponse' object is not subscriptable,2023-05-17.0393,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/393,"I should use remain_docs.code and remain_docs.data, right? Is it?",112
113,[BUG] Error message when loading chatglm model: 'NoneType' object has no attribute 'message_types_by_name',2023-05-17.0398,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/398,**Problem Description**,113
114,"[BUG] Python webui.py execution does not report an error, but the ui interface prompts Something went wrong Expecting value: line 1 column 1 (char 0",2023-05-18.0399,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/399,**Environment Configuration**,114
115,"After starting, the API interface is called normally, and after a while, it will continue to burst Since the angle classifier is not initialized",2023-05-18.0404,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/404,**Problem Description**,115
116,"[BUG] write_check_file method, the open function does not specify the encoding",2023-05-18.0408,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/408,"def write_check_file(filepath, docs):",116
117,"If there is an image in the imported PDF, there is a high probability that the "unsupported colorspace for 'png'" exception will occur",2023-05-18.0409,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/409,"pix = fitz. Pixmap(doc, img[0])",117
118,What software is used to draw the flowchart?,2023-05-18.0410,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/410,draw.io,118
119,Mac failed to load the model,2023-05-19.0417,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/417,Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.,119
120,"If you use the GPU to run the knowledge base Q&A locally, an exception occurs when the first question is asked.",2023-05-20.0419,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/419,The configuration file model_config.py is:,120
121,I want to join a discussion group,2023-05-20.0420,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/420,OK,121
122,"Is there an API that calls LLM directly, currently only the API of the knowledge base?",2023-05-22.0426,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/426,-------------------------------------------------------------------------------,122
123,ERROR __init__() got an unexpected keyword argument 'autodetect_encoding' after uploading a file,2023-05-22.0428,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/428,"This issue occurs after uploading a file: ERROR 2023-05-22 11:46:19,568-1d: __init__() got an unexpected keyword argument 'autodetect_encoding'",123
124,I would like to ask what software is used to draw the flowchart used in the README,2023-05-22.0431,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/431,**Feature Description**,124
125,No matching distribution found for langchain==0.0.174,2023-05-23.0436,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/436,ERROR: Could not find a version that satisfies the requirement langchain==0.0.174,125
126,Is bing a must?,2023-05-23.0437,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/437,"From this [footsteps] (https://github.com/imClumsyPanda/langchain-ChatGLM/blob/master/configs/model_config.py#L129), I found that I need to apply for Bing API, but if I don't apply, can't I reason purely with a model?",126
127,"The 5.22 update langchain-chatglm v0.1.13 and previous versions are deployed in the same environment, and the response speed is significantly slower",2023-05-23.0442,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/442,The new langchain-chatglm v0.1.13 version is slow,127
128,Error reported during startup,2023-05-23.0443,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/443,Traceback (most recent call last):,128
129,"ValueError: not enough values to unpack (expected 2, got 1)on of the issue",2023-05-24.0449,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/449,"File ".cache\huggingface\modules\transformers_modules\chatglm-6b-int4\modeling_chatglm.py", line 1280, in chat",129
130,"[BUG] API deployment, streaming output functions, missing a question",2023-05-24.0451,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/451,**Problem Description**,130
131,The simplicity of the project structure is maintained,2023-05-24.0454,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/454,**Feature Description**,131
132,The program can't scan the code to enter,2023-05-24.0455,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/455,"I can't scan the code in the project group, can I add WeChat to pull me into the group, thank you! WeChat: daniel-0527",132
133,"Ask me to join the group to discuss, Haishuo one, focusing on LLM and other related technologies",2023-05-24.0461,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/461,**Feature Description**,133
134,[BUG] OSError: Error no file named pytorch_model.bin found in directory /chatGLM/model/model-6b for chatglm-6b model,2023-05-26.0474,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/474,**1. Brief description:**,134
135,"Now the QR code of the exchange group of this project cannot be scanned, and the group owner needs to pass",2023-05-27.0478,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/478,"Now the QR code of the exchange group of this project cannot be scanned, and the group owner needs to pass",135
136,RuntimeError: Only Tensors of floating point and complex dtype can require gradients,2023-05-28.0483,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/483,Just updated to the latest version:,136
137,RuntimeError: "LayerNormKernelImpl" not implemented for 'Half',2023-05-28.0484,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/484,"Solved the problem that params only uses two arguments {'trust_remote_code': true, 'torch_dtype': torch.float16}",137
138,"[BUG] The file did not load successfully, please re-upload the file",2023-05-31.0504,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/504,webui.py,138
139,"[BUG] bug 17 ,Why is pdf and pdf different? Why are some PDFs recognized? Some PDFs can't be recognized?",2023-05-31.0506,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/506,"Bug 17, why is PDF and PDF different? Why are some PDFs recognized? Some PDFs can't be recognized?",139
140,[FEATURE] Concise description of the feature,2023-05-31.0513,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/513,**Feature Description**,140
141,[BUG] webui.py Failed to load chatglm-6b-int4,2023-06-02.0524,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/524,**Problem Description**,141
142,[BUG] webui.py Abnormal loading of chatglm-6b model,2023-06-02.0525,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/525,**Problem Description**,142
143,Added support for ChatGPT embedding and API calls,2023-06-02.0531,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/531,Can OpenAI's Embedding API and Conversational API be supported?,143
144,[FEATURE] ADJUSTS THE LOCATION WHERE THE MODEL IS DOWNLOADED,2023-06-02.0537,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/537,"By default, the model is downloaded to $HOME/.cache/huggingface/, and the download of the model cannot be completed when the space on the C drive is insufficient. There are also no parameters in configs/model_config.py to adjust the position of the model.",144
145,[BUG] langchain=0.0.174 error,2023-06-04.0543,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/543,**Problem Description**,145
146,[BUG] The local model path is not loaded correctly after the update,2023-06-05.0545,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/545,**Problem Description**,146
147,"SystemError: 8-bit model requires CUDA support, or use a quantized model instead!",2023-06-06.0550,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/550,"After docker is deployed, start docker, and after a while, the container will automatically exit with the error SystemError: The 8-bit model needs CUDA support, or use the quantized model instead! [NVIDIA Container Toolkit] (https://github.com/NVIDIA/nvidia-container-toolkit) is also installed",147
148,[BUG] An error occurs when the knowledge base is uploaded for more than 1 MB,2023-06-06.0556,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/556,**Problem Description**,148
149,"After enabling AS access, an error message is still reported and cannot be requested",2023-06-06.0560,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/560,Error message:,149
150,dialogue_answering Is the code not being used? and did not see the call,2023-06-07.0571,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/571,dialogue_answering What are you doing?,150
151,"[BUG] The response time is extremely slow, where should I start to optimize? 48C/128G/8 cards",2023-06-07.0573,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/573,Operating environment: ubuntu20.04,151
152,An error message is reported when running cli_demo a CPU-only environment indicates that the nvcuda.dll cannot be found,2023-06-08.0576,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/576,"The on-premise environment is CPU-only, and the previous version runs normally in the CPU-only environment, but encode problems often occur when uploading the local knowledge base. After restarting the git project today, the following problem occurred during the runtime, how can I solve it?",152
153,How to load a local embedding model (text2vec-large-Chinese model file),2023-06-08.0582,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/582,"Because it needs to be deployed offline, so I want to put the model locally, I modified the HuggingFaceEmbeddings() in chains/local_doc_qa.py, and added a cache_folder parameter to it, so that the downloaded file is in the cache_folder, and the model_name is text2vec-large-Chinese. For example, cache_folder='/home/xx/model/text2vec-large-Chinese', model_name='text2vec-large-Chinese', you still need to download an online network to report an error, how can the boss solve this problem?",153
154,"ChatGLM-6B is installed on another server, how can I modify the interface of model.cofnig.py to use it?",2023-06-09.0588,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/588,"I originally wanted to add an api base url here, but running web.py discovery will still go to HuggingFace to download the model",154
155,[BUG] raise partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' when call interface `upload_file`,2023-06-10.0591,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/591,**Problem Description**,155
156,[BUG] raise OSError: [Errno 101] Network is unreachable when call interface upload_file and upload .pdf files,2023-06-10.0592,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/592,**Problem Description**,156
157,"If you directly use Vicina as the base model, what are the areas that need to be modified?",2023-06-12.0596,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/596,"Does the Vicuna model have a direct conversion? That is, the vicuna after the conversion of llama.",157
158,[BUG] AttributeError: 'NoneType' object has no attribute 'get' error is thrown when calling api via cli.py,2023-06-12.0598,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/598,"When calling the API via the 'python cli.py start api --ip localhost --port 8001' command, it throws:",158
159,[BUG] 'langchain-ChatGLM: error: unrecognized arguments: start cli' error message when calling api via cli.py,2023-06-12.0601,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/601,"When starting a cli_demo with the Python cli.py Start CLI, an error message is reported:",159
160,[BUG] error: unrecognized arguments: --model-dir conf/models/,2023-06-12.0602,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/602,Have the keyword parameters been modified? Is there any documentation? Big guy,160
161,[BUG] Failed to upload all files,2023-06-12.0603,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/603,ERROR:    Exception in ASGI application,161
162,[BUG] config fails to start with chatyuan,2023-06-12.0604,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/604,"chatyuan": {,162
163,"After using the fashchat API, the API is reported in the background as shown in the figure",2023-06-12.0606,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/606,I follow the https://github.com/imClumsyPanda/langchain-ChatGLM/blob/master/docs/fastchat.md,163
164,"[BUG] Enabling contextual linking, each embedding search will find more than the previous one",2023-06-13.0613,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/613,**Problem Description**,164
165,"local_doc_qa.py MyFAISS.from_documents () is not a good idea. There is no such method in the MyFAISS class, and there are only from_texts methods in its parent FAISS and VectorStore [BUG] Concise description of the issue",2023-06-14.0619,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/619,"local_doc_qa.py MyFAISS.from_documents () is not a good idea. This method is not present in the MyFAISS class, and there are only from_texts methods in its parent classes FAISS and VectorStore",165
166,[BUG] TypeError: similarity_search_with_score_by_vector() got an unexpected keyword argument 'filter',2023-06-14.0624,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/624,**Problem Description**,166
167,please delete this issue,2023-06-15.0633,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/633,"sorry, incorrect submission. Please remove this issue!",167
168,[BUG] vue front-end image build failed,2023-06-15.0635,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/635,**Problem Description**,168
169,Can the ChatGLM-6B model answer questions in English?,2023-06-15.0640,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/640,"Boss, may I ask, if the local knowledge document is in English, can the ChatGLM-6B model answer English questions? If not, there is no alternative model recommendation, looking forward to your reply, thank you",169
170,[BUG] Concise description of the issue,2023-06-16.0644,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/644,**Problem Description**,170
171,KeyError: 3224,2023-06-16.0645,https://github.com/imClumsyPanda/langchain-ChatGLM/issues/645,```,171