{"title": "Come on~ and some suggestions", "file": "2023-03-31.0002", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/2", "detail": "Come on, I think you're going in the right direction."} , "id": 0}
{"title": "What is the current operating environment, windows or Linux", "file": "2023-04-01.0003", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/3", "detail": "What is the current operating environment, windows or Linux, What version of python is it? ", "id": 1}
{"title": "Is this running on top of CLM?"} , "file": "2023-04-01.0004", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/4", "detail": "Do I need to install CLM locally and run it normally, and then follow the steps in this article to run?" , "id": 2}
{"title": "[reproduce the problem] The text extracted from the knowledge base when constructing the prompt is garbled", "file": "2023-04-01.0005", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/5", "detail": "hi, I am trying to reproduce the effect in the README, and I also used it ChatGLM-6B's README was used as input text, but it was found that the text extracted from the knowledge base was garbled, resulting in the constructed prompt being unavailable. Want to know how to fix this. ", "id": 3}
{"title": "Can contextual dialogue be added later?"} , "file": "2023-04-02.0006", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/6", "detail": "The function of historical messaging has been implemented in the current get_wiki_agent_answer function, Later, I will confirm whether the chat_history is passed during the model call in Langchain. ", "id": 4}
{"title": "Excuse me: Is it OK to have a pure CPU?"} , "file": "2023-04-03.0007", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/7", "detail": "Cool implementation, greatly expanded my horizons! Runs smoothly on the GPU", "id": 5}
{"title": "Error: 'NoneType' object has no attribute 'message_types_by_name'", "file": "2023-04-03.0008", "url": " https://github.com/imClumsyPanda/langchain-ChatGLM/issues/8", "detail": "Error:", "id": 6}
{"title": "Runtime: How big does the GPU need to be?"} "file": "2023-04-03.0009", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/9", "detail": "If you follow THUDM/ChatGLM-6B, the GPU size used should be around 13GB, but after running the script, 24GB is not enough." , "id": 7}
{"title": "What is the format of local knowledge?"} , "file": "2023-04-03.0010", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/10", "detail": "The tested format includes the text information in the docx and md files [langchain documentation] (https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/unstructured_file.html?highlight=pdf#)", "id": 8}
{"title": "24G of video memory is still blown up, does it support dual-SIM operation", "file": "2023-04-03.0011", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/11", "detail": "RuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 23.70 GiB total capacity; 22.18 GiB already allocated; 12.75 MiB free; 22.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF", "id": 9}
{"title": "How do you know that the embeddings method is the same as the model training method?", "file": "2023-04-03.0012", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/12", "detail": " The methods of embedding and LLM do not need to be the same, embedding can solve the needs of semantic retrieval. The embedding used in this project is the process of indexing local knowledge and converting questions into vectors. ", "id": 10}
{"title": "Is it possible to provide the format of the local knowledge file?"} "file": "2023-04-04.0013", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/13", "detail": "Is it possible to provide the format of the local knowledge file?" , "id": 11}
{"title": "Is it possible to run a card below 8G like the original Tsinghua version?"} , "file": "2023-04-04.0016", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/16", "detail": "Is it possible to run a card below 8G like the original Tsinghua version?" My 8G card has ðŸ¤£ðŸ¤£ðŸ¤£ exploded", "id": 12}
{"title": "Please teach langchain to coordinate the use of vector libraries and chatGLM to work", "file": "2023-04-05.0018", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/18", "detail": "This paragraph in the code is to create a question and answer model, Will access ChatGLM and the vector library of the local corpus, what is the priority of langchain when answering? Search the vector library first, didn't find chatglm again? Or what mechanism? ", "id": 13}
{"title": "ValueError: 150001 is not in list is not in list exception thrown on mac m2max", "file": "2023-04-05.0019", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/19", "detail": " I changed the code chatglm_llm.py load the model to the following", "id": 14}
{"title": "The program has been stuck after running", "file": "2023-04-05.0020", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/20", "detail": "Thank you for your efforts, but I have a problem running it, please help."} , "id": 15}
{"title": "Ask about the logic of chat_history", "file": "2023-04-06.0022", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/22", "detail": "Thanks for open source."} , "id": 16}
{"title": "Why does it load checkpoint every time I run it", "file": "2023-04-06.0023", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/23", "detail": "After I downloaded this embedding model to my local computer, Doesn't start properly. ", "id": 17}
{"title": "Can I upload some examples for my local knowledge file?"} , "file": "2023-04-06.0025", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/25", "detail": "As the question, how to construct a knowledge file with a better effect? Can you provide a sample", "id": 18}
{"title": "What version of you are using?", "file": "2023-04-06.0026", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/26", "detail": "Hi Panda, I saw the `pip install -r requirements` command in README, and want to confirm you are using python2 or python3? because my pip and pip3 version are all is 22.3.", "id": 19}
{"title": "Friends who are interested in communicating the application of this project can add a WeChat group", "file": "2023-04-07.0027", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/27", "detail": "! [IMG_1630] (https://user-images.githubusercontent.com/5668498/230533162-8b9bfcdd-249c-4efe-b066-4f9ba2ce9f23.jpeg)", "id": 20}
{"title": "The more local knowledge, the longer the retrieval time will be when answering", "file": "2023-04-07.0029", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/29", "detail": "Yes because vector matching retrieval is required", "id": 21}
{"title": "Why do you still cry in the end?" , "file": "2023-04-07.0030", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/30", "detail": "Failed to import transformers.models.t5.configuration_t5 because of the following error (look up to see", "id": 22}
{"title": "UnicodeDecodeError: 'utf-8' codec can't decode", "file": "2023-04-07.0031", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/31", " detail": "The first time the conversation is fine, the model returns the output and then gives me your question, I enter the question again, and the error is reported", "id": 23}
{"title": "The quantized version of in4 is used to apply for 10Gb of video memory when reasoning", "file": "2023-04-07.0033", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/33", "detail": "File \"/root/. cache/huggingface/modules/transformers_modules/chatglm-6b-int4-qe/modeling_chatglm.py\", line 581, in forward", "id": 24}
{"title": "Running with colab, python3.9, prompts package import problem", "file": "2023-04-07.0034", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/34", "detail": "from ._util import is_ directory, is_path", "id": 25}
{"title": "Failed to run, Loading checkpoint was not killed before reaching 100%, what is the reason?"} , "file": "2023-04-07.0035", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/35", "detail": "The log is as follows:", "id": 26}
{"title": "I made a communication group, I can't get a lot of details by myself, everyone discusses technology and adds connection-image I'll pull you", "file": "2023-04-08.0036", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/36", "detail": " I don't know how much I don't know about it.,Let's get it together.ã€‚ã€‚ Ready to make a deployment problem solving document out", "id": 27}
{"title": "Error using the new version with langchain", "file": "2023-04-09.0043", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/43", "detail": "Error with the new changes:", "id": 28}
{"title": "How to solve the error reported by the program torch.cuda.OutOfMemoryError?"} , "file": "2023-04-10.0044", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/44", "detail": "Error details are as follows:", "id": 29}
{"title": "How is the training data format set for QA", "file": "2023-04-10.0045", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/45", "detail": "This project is not a fine-tuning method, so it does not involve the training process." , "id": 30}
{"title": "The FileType.UNK file type is not supported in partition. Solution", "file": "2023-04-10.0046", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/46", "detail": "ValueError: Invalid file /home/yawu/Documents/ langchain-ChatGLM-master/data. The FileType.UNK file type is not supported in partition.", "id": 31}
{"title": "How do I read multiple txt documents?"} , "file": "2023-04-10.0047", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/47", "detail": "As questioned, how do I read multiple txt documents?" In the example code, there is only a case of reading one document, and I can only specify one document after I replace this input with string, and I can't specify multiple documents with wildcards, and I can't pass in a list of multiple file paths. ", "id": 32}
{"title": "nltk package unable to either download or load local nltk_data folder", "file": "2023-04-10.0049", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/49", " detail": "I'm running this project on an offline Windows Server environment so I download the Punkt and averaged_perceptron_tagger tokenizer in this directory:", "id": 33}
{"title": "Langchain version needs to be specified in requirements.txt", "file": "2023-04-11.0055", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/55", "detail": " RetrievalQA cannot be introduced under langchain version 0.116, you need to specify a later version (no problem under version 0.136)", "id": 34}
{"title": "Demo cannot give output content", "file": "2023-04-12.0059", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/59", "detail": "Hello, I tested the project's own press release sample and a self-uploaded text, which can be loaded, But I can't give an answer, what is the situation and how to solve it, thank you. PS: 1. I just downloaded all the codes this morning; 2. The hardware server meets the requirements; 3. Operate normally according to the operating instructions. ", "id": 35}
{"title": "There are too many people in the group to join the group, please help pull into the group", "file": "2023-04-12.0061", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/61", "detail": "Hello, the number of people in your group exceeds 200, and you can't join the group through the QR code at present, Is it convenient for you to add me to WeChat and pull me into the group? Thank you very much", "id": 36}
{"title": "The number of people in the group is full, ask the big guy to join the group", "file": "2023-04-12.0062", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/62", "detail": "The QR code for pulling the group has been updated in the README", "id": 37}
{"title": "Langchain version error in requirements", "file": "2023-04-12.0065", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/65", "detail": " The langchain version should be 0.0.12 instead of 0.0.120", "id": 38}
{"title": "Linux : Searchd in", "file": "2023-04-13.0068", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/68", "detail": "import nltk", "id": 39}
{"title": "No sentence-transformers model found", "file": "2023-04-13.0069", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/69", "detail": "This model cannot be loaded, The reason for the error is that the model cannot be found, but the path is configured", "id": 40}
{"title": "Error loading punkt: <urlopen error [Errno 111] Connection", "file": "2023-04-13.0070", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/70", " detail": "An NLTK error occurs knowledge_based_chatglm.py running, as follows:", "id": 41}
{"title": "[Don't understand] ptuning dataset format", "file": "2023-04-13.0072", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/72", "detail": "Hello everyone, is there any mystery in fine-tuning the format of the dataset?" I see ChatGLM-6B/ptuning/readme.md, why is the content in the demo dataset ADGEN written as Type#skirt*style#simplicity This format? What's the mystery here? "id": 42}
{"title": "Embedding model", "file": "2023-04-13.0074", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/74", "detail": "Hello, I see that the embedding model in the project uses: GanymedeNil/text2vec-large-Chinese, can the embedding model in this project directly use ChatGLM? ", "id": 43}
{"title": "Macbook M1 is running webui.py and an error is reported, can I support M-series chips", "file": "2023-04-13.0080", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/80", "detail": "'''", "id": 44}
{"title": "new feature: Add support for P-tunningv2 fine-tuned model", "file": "2023-04-14.0099", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/99", "detail": "Can I add a new feature? Loading support for models after fine-tuning chatglm using [P-tunningv2](https://github.com/THUDM/ChatGLM-6B/tree/main/ptuning)", "id": 45}
{"title": "The txt file is loaded successfully, but an error is reported when it is read", "file": "2023-04-15.0106", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/106", "detail": "The latest version of the code."} What's weird is that my computer doesn't have a D drive, why is there a D disk in the error message...", "id": 46}
{"title": "Model loaded successfully?"} The file cannot be imported. ", "file": "2023-04-15.0107", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/107", "detail": "All models are local." , "id": 47}
{"title": "What operating system do you use?"} , "file": "2023-04-16.0110", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/110", "detail": "ubuntu, centos or windows?" , "id": 48}
{"title": "Error ModuleNotFoundError: No module named 'configs.model_config'", "file": "2023-04-17.0112", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/112", " detail": "After updating the code, run webui.py and get the error ModuleNotFoundError: No module named 'configs.model_config'. No workaround found. ", "id": 49}
{"title": "Asking a specific question will cause the video memory to explode", "file": "2023-04-17.0116", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/116", "detail": "It's okay to ask a question normally."} , "id": 50}
{"title": "Loading can't get in?"} , "file": "2023-04-18.0127", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/127", "detail": "python webui.py on linux system, after opening the web page, it has been loading, Does it have something to do with the fact that I didn't have detectron2 installed? ", "id": 51}
{"title": "Limit the amount of local knowledge content?"} , "file": "2023-04-18.0129", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/129", "detail": "The local knowledge file type is txt, more than 5 pieces of data, and the video memory will explode when you ask a question." , "id": 52}
{"title": "I was planning to make a similar product, it seems that I don't have to start from scratch", "file": "2023-04-18.0130", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/130", "detail": "Text cutting, is there room for optimization?"} WeChat groups can no longer be added. ", "id": 53}
{"title": "load model failed. Failed to load model", "file": "2023-04-18.0132", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/132", "detail": "'''", "id": 54}
{"title": "How do I answer in the webui and return the referenced local data content at the same time?"} , "file": "2023-04-18.0133", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/133", "detail": "as titled", "id": 55}
{"title": "I can't add more people to the group with 200 people, can you give me the contact information of the person in charge to pull me into the group?"} , "file": "2023-04-20.0143", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/143", "detail": "id": 56}
{"title": "No sentence-transformers model found with name '/text2vec/', but there is indeed a model file under the path", "file": "2023-04-20.0145", "url": " https://github.com/imClumsyPanda/langchain-ChatGLM/issues/145", "detail": "Also:The dtype of attention mask (torch.int64) is not bool", "id": 57}
{"title": "Where is the path to load the model modified, by default it seems to be preceded by transformers_modules.", "file": "2023-04-20.0148", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/148", "detail": "<."} img width=\"1181\" alt=\"1681977897052\" src=\"https://user-images.githubusercontent.com/30926001/233301106-3846680a-d842-41d2-874e-5b6514d732c4.png\">", "id": 58}
{"title": "Why does it get an error when I put it in a method call, and how do I deal with this?"} , "file": "2023-04-20.0150", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/150", "detail": "```python", "id": 59}
{"title": "No sentence-transformers model found with name C:\\Users\\Administrator/.cache\\torch\\sentence_transformers\\GanymedeNil_text2vec-large-Chinese. Creating a new one with MEAN pooling.", "file": "2023-04-21.0154", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/154", "detail": "Is it normal to be stuck in this area for a long time", "id": 60}
{"title": "WeChat group needs to be invited to join", "file": "2023-04-21.0155", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/155", "detail": "RT", "id": 61}
{"title": "No sentence-transformers model found with name GanymedeNil/text2vec-large-Chinese. Creating a new one with MEAN pooling", "file": "2023-04-21.0156", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/156", "detail": "ls GanymedeNil/ text2vec-large-Chinese", "id": 62}
{"title": "Embedding will load twice", "file": "2023-04-23.0159", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/159", "detail": "Hello, why do you want to set it up like this, it will load twice."} , "id": 63}
{"title": "The group added by scanning the QR code, the group members are full and can't enter", "file": "2023-04-23.0160", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/160", "detail": "as title", "id": 64}
{"title": "Execute python3 cli_demo.py Error message AttributeError: 'NoneType' object has no attribute 'chat'", "file": "2023-04-24.0163", "url": " https://github.com/imClumsyPanda/langchain-ChatGLM/issues/163", "detail": "At first I suspected that it was a memory shortage problem, but it didn't work if I replaced it with int4, int4-qe, does anyone know what the reason is", "id": 65}
{"title": "Match Score", "file": "2023-04-24.0167", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/167", "detail": "In example cli_ The matching text returned in demo.py does not have a corresponding score, can this feature be added", "id": 66}
{"title": "Does the big guy have any plans to add typewriter functions to web_ui.py", "file": "2023-04-25.0170", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/170", "detail": "Now after loading the knowledge base, the single sheet V100."} 32G also needs more than 20S to answer questions in the vertical field, and the experience of using it without typewriter verbatim output is still more painful....", "id": 67}
{"title": "Is it possible to use a verctorDB for the embedings?", "file": "2023-04-25.0171", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/171", "detail": "when I play, I have to load the local data again and again when to start. I wonder if it is possible to use", "id": 68}
{"title": "How do I load the fine-tuning model file that I get from training the official model with LoRa?"} , "file": "2023-04-25.0173", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/173", "detail": "Get the following file by LoRa training:", "id": 69}
{"title": "Where's the code from langchain.chains import RetrievalQA?"} , "file": "2023-04-25.0174", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/174", "detail": "local_doc_qa.py", "id": 70}
{"title": "Where's the knowledge_based_chatglm.py file?"} Why can't I find it?? Was it replaced with a cli_demo.py file? ", "file": "2023-04-26.0175", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/175", "detail": "Where can I find knowledge_based_chatglm.py file? Why can't I find it?? Was it replaced with a cli_demo.py file? ", "id": 71}
{"title": "AttributeError: 'Chatbot' object has no attribute 'value'", "file": "2023-04-26.0177", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/177", "detail" : "Traceback (most recent call last):", "id": 72}
{"title": "Console api.py alert", "file": "2023-04-26.0178", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/178", "detail": "you must pass the application as an import."} string to enable \"reload\" or \"workers\"", "id": 73}
{"title": "How to join a group chat", "file": "2023-04-27.0183", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/183", "detail": "There are more than 200 people in the WeChat group, I need to be invited, how to join?" , "id": 74}
{"title": "How to combine Chatglm with local knowledge", "file": "2023-04-27.0185", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/185", "detail": "Hello, I'd like to ask you how you can combine the text that the knowledge base matches with the chatglm generated, instead of saying that if you don't find it, you can't answer the question based on the known information, thank you", "id": 75}
{"title": "A little suggestion", "file": "2023-04-27.0189", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/189", "detail": "1.weiui get_vector_ store method, add an upload exception caused by the judgment to be compatible with the gradio version", "id": 76}
{"title": "In the Windows environment, follow the tutorial to configure the Conda environment, git the project, modify the model path, run the demo and report a missing error", "file": "2023-04-28.0194", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/194", " detail": "The error code is as follows:", "id": 77}
{"title": "ValueError: too many values to unpack (expected 2)", "file": "2023-04-28.0198", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/198", "detail": "When i tried to use the non-streaming, `ValueError: too many values to unpack (expected 2)` error came out.", "id": 78}
{"title": "Overwrite the original knowledge after loading the doc", "file": "2023-04-28.0201", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/201", "detail": "After loading a large amount of private knowledge base, the original knowledge will be overwritten", "id": 79}
{"title": "The answer effect of the custom knowledge base is very poor", "file": "2023-04-28.0203", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/203", "detail": "Is it because the amount of data is too small that the answer effect of the custom knowledge base knowledge base is very poor", " id": 80}
{"title": "Under python310, pycocotools installation failed, indicating that the earlier version cython, the higher version is actually installed", "file": "2023-04-29.0208", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/208", "detail": "RT."} ,Pure offline environment installation,It is very difficult to rely on the installation,Finally, I encountered pycocotools,I have never been able to install it,Ask for advice! ", "id": 81}
{"title": "[FEATURE] supports RWKV models (pip package & rwkv.cpp etc.)", "file": "2023-05-01.0216", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/216", "detail": " Hello, I am the author of RWKV, the introduction sees: https://zhuanlan.zhihu.com/p/626083366", "id": 82}
{"title": "[BUG] Why can't the host/server start the service properly when it is not connected to the Internet?} , "file": "2023-05-02.0220", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/220", "detail": "**Problem Description**", "id": 83}
{"title": "[BUG] Concise description of the issue", "file": "2023-05-03.0222", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/222", "detail": "**local."} variable 'torch' referenced before assignment**", "id": 84}
{"title": "Chinese input of txt files is not supported", "file": "2023-05-04.0235", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/235", "detail": "vs_path, _ = local_doc_qa.init_ knowledge_vector_store(filepath)", "id": 85}
{"title": "None of the files were loaded successfully, please check the dependencies or replace them with other files to upload again."} The file is not loaded successfully, please re-upload the file", "file": "2023-05-05.0237", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/237", "detail": "Please help solve it, thank you!" , "id": 86}
{"title": "[BUG]chatglm model is loaded twice when using multi-card", "file": "2023-05-05.0241", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/241", "detail": "chatglm_ llm.py The chatglm model is loaded once on line 129 and again on line 143 of the file", "id": 87}
{"title": "[BUG] score result error when similarity_search_with_score_by_vector function returns multiple docs", "file": "2023-05-06.0252", "url": " https://github.com/imClumsyPanda/langchain-ChatGLM/issues/252", "detail": "Problem Description", "id": 88}
{"title": "Can I create another communication group, this group is full and I can't get in."} , "file": "2023-05-06.0255", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/255", "detail": "It should have been updated in the readme in the morning, if you can't add it may be a web cache problem, you can try to scan img/qr_code_12 directly. jpg", "id": 89}
{"title": "What is this bug wow?"} KeyError: 'serialized_input'", "file": "2023-05-06.0257", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/257", "detail": "What is the error after running "python webui.py"? How to solve it? ", "id": 90}
{"title": ""Where can I change the code and run it on the CPU?"} , "file": "2023-05-06.0258", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/258", "detail": "**Problem Description**", "id": 91}
{"title": "ModuleNotFoundError: No module named 'modelscope'", "file": "2023-05-07.0266", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/266", "detail": "Install this."} ", "id": 92}
{"title": "When loading a LoRa fine-tuning model, the LoRa parameters are loaded successfully, but the model is not loaded successfully?"} "file": "2023-05-08.0270", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/270", "detail": "What is the reason?" , "id": 93}
{"title": "[BUG] Run webui.py with the error: name 'EMBEDDING_DEVICE' is not defined", "file": "2023-05-08.0274", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/274", "detail."} ": "Solved, I changed this variable wrong when I modified the model_config", "id": 94}
{"title": "Based on ptuning training, both the new and old models have been loaded, but only the new ones", "file": "2023-05-08.0280", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/280", "detail": "licitly passing a ' revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.", "id": 95}
{"title": "[BUG] When using the chatyuan model, the dialogue Error, has no attribute 'stream_chat'", "file": "2023-05-08.0282", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/282", " detail": "Problem Description", "id": 96}
{"title": "There is a stop _call prompt during chaglm call", "file": "2023-05-09.0286", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/286", "detail": "**Feature Description."} Description**", "id": 97}
{"title": "Logger._log() got an unexpected keyword argument 'end'", "file": "2023-05-10.0295", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/295", "detail": " When using cli_demo, load a normal txt file, and after entering the problem, the error message is displayed: "TypeError: Logger._log() got an unexpected keyword argument 'end'"", "id": 98}
{"title": "[BUG] Can you explain the purpose of this FAISS.similarity_search_with_score_by_vector = similarity_search_with_score_by_vector", "file": "2023-05-10.0296", "url":  "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/296", "detail": "I don't quite understand what this library does by writing its own similarity_search_with_score_by_vector methods, because langchain is the original similarity_search_ with_score_by_vector just search faiss and then combine the returned topk sentences. I don't think there's anything wrong with the original, but I didn't understand much about what else was done in this library, because there were no notes. ", "id": 99}
{"title": "[BUG] Upload Chinese filename file under Windows, faiss cannot generate vector database file", "file": "2023-05-11.0318", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/318", "detail": "**Problem / Problem Description**", "id": 100}
{"title": "Can the streaming output in the cli_demo follow the output of the previous answer?", "file": "2023-05-11.0320", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/320", "detail": "The existing streaming output result is style:", "id": 101}
{"title": "The webpage cannot be loaded during intranet deployment, can offline static resources be added", "file": "2023-05-12.0326", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/326", "detail": "The webpage cannot be loaded during intranet deployment, can offline static resources be added", "id."I."} ": 102}
{"title": "I want to change the encoding format of the file characters to encoding='utf-8', because there will be an ASCII codec can't decode byte error", "file": "2023-05-14.0360", "url": " https://github.com/imClumsyPanda/langchain-ChatGLM/issues/360", "detail": "An error occurs when uploading a Chinese txt file with UTF-8 encoding", "id": 103}
{"title": "Where is the progress bar for Batches set?"} Can I turn off the display?", "file": "2023-05-15.0366", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/366", "detail": "When using cli_demo.py for command-line testing, there is a progress bar for each sentence before each answer", "id": 104}
{"title": "ImportError: dlopen: cannot load any more object with static TLS or Segmentation fault", "file": "2023-05-15.0368", "url": " https://github.com/imClumsyPanda/langchain-ChatGLM/issues/368", "detail": "Problem Description", "id": 105}
{"title": "Error error when reading PDF", "file": "2023-05-16.0373", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/373", "detail": "Execute on Colab cli_ demo.py, a pdf file is placed in the path folder, and an error is displayed during the loading process, and then the PDF file cannot be loaded", "id": 106}
{"title": "[BUG] webui error InvalidURL", "file": "2023-05-16.0375", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/375", "detail": "python version: 3.8.16", "id": 107}
{"title": "[FEATURE] What should I do if I let the answer not contain the source", "file": "2023-05-16.0380", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/380", "detail": "**Feature Description."] Description**", "id": 108}
{"title": "Unsupported colorspace for 'png'", "file": "2023-05-16.0381", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/381", "detail": "**Problem / Problem Description**", "id": 109}
{"title": "'ascii' codec can't encode characters in position 14-44: ordinal not in range(128) classic bug", "file": "2023-05-16.0382", "url": " https://github.com/imClumsyPanda/langchain-ChatGLM/issues/382", "detail": "This problem arises when you have a conversation after adding a knowledge base, and then you add a knowledge base." , "id": 110}
{"title": "The number of people in the WeChat group is more than 200, and I can't enter it by scanning the code, can the group owner create a new group", "file": "2023-05-17.0391", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/391", "detail": "**Feature Description."] Description**", "id": 111}
{"title": "TypeError: 'ListDocsResponse' object is not subscriptable", "file": "2023-05-17.0393", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/393", "detail": "I should use remain_docs.code and remain_docs.data, right?" Is it? ", "id": 112}
{"title": "[BUG] Error message when loading chatglm model: 'NoneType' object has no attribute 'message_types_by_name'", "file": "2023-05-17.0398", "url": " https://github.com/imClumsyPanda/langchain-ChatGLM/issues/398", "detail": "Problem Description", "id": 113}
{"title": "[BUG] Executing python webui.py does not report an error, but the ui interface prompts Something went wrong Expecting value: line 1 column 1 (char 0", "file": "2023-05-18.0399", "url":  "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/399", "detail": "**environment configuration**", "id": 114}
{"title": "After startup, the API interface is called normally, and after a while, it will keep bursting Since the angle classifier is not initialized", "file": "2023-05-18.0404", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/404."] ", "detail": "Problem Description", "id": 115}
{"title": "[BUG] In the write_check_file method, the open function does not specify the encoding", "file": "2023-05-18.0408", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/408", "detail": "def write_ check_file(filepath, docs):", "id": 116}
{"title": "There is a high probability that there is an image in the imported PDF, there is a high probability that "unsupported colorspace for 'png'" exception", "file": "2023-05-18.0409", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/409", "detail" : "pix = fitz. Pixmap(doc, img[0])", "id": 117}
{"title": "What software is used to draw the flowchart", "file": "2023-05-18.0410", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/410", "detail": "draw.io", "id": 118}
{"title": "mac failed to load model", "file": "2023-05-19.0417", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/417", "detail": "Explicitly passing a 'revision' is encouraged."} when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.", "id": 119}
{"title": "Ran the knowledge base Q&A locally on the GPU, and the first question asked was abnormal."} , "file": "2023-05-20.0419", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/419", "detail": "profile model_config.py is:", "id": 120}
{"title": "Want to join a discussion group", "file": "2023-05-20.0420", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/420", "detail": "OK", "id": 121}
{"title": "Is there an API that calls LLM directly, currently only the knowledge base API?"} , "file": "2023-05-22.0426", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/426", "detail": "------------------------------------------------------------------------------- ", "id": 122}
{"title": "ERROR after uploading a file __init__() got an unexpected keyword argument 'autodetect_encoding'", "file": "2023-05-22.0428", "url": " https://github.com/imClumsyPanda/langchain-ChatGLM/issues/428", "detail": "This issue occurs after uploading a file: ERROR 2023-05-22 11:46:19,568-1d: __init__() got an unexpected keyword argument ' autodetect_encoding'", "id": 123}
{"title": "I want to ask what software is used to draw the flowchart used in the README", "file": "2023-05-22.0431", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/431", "detail": "**Feature Description** ", "id": 124}
{"title": "No matching distribution found for langchain==0.0.174", "file": "2023-05-23.0436", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/436", "detail": " ERROR: Could not find a version that satisfies the requirement langchain==0.0.174 ", "id": 125}
{"title": "Is [FEATURE] bing mandatory?" , "file": "2023-05-23.0437", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/437", "detail":  "From this [footsteps] (https://github.com/imClumsyPanda/langchain-ChatGLM/blob/master/configs/model_config.py#L129), I found that I need to apply for the Bing API, if I don't apply, can't I just use the model to reason?" , "id": 126}
{"title": "langchain-chatglm v0.1.13 and previous versions of update 5.22 deployed in the same environment, the reply speed is significantly slower", "file": "2023-05-23.0442", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/442", " detail": "The new langchain-chatglm v0.1.13 version is slow", "id": 127}
{"title": "Error reported during startup", "file": "2023-05-23.0443", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/443", "detail": "Traceback (most recent call last):", "id": 128}
{"title": "ValueError: not enough values to unpack (expected 2, got 1)on of the issue", "file": "2023-05-24.0449", "url": " https://github.com/imClumsyPanda/langchain-ChatGLM/issues/449", "detail": "File \".cache\\huggingface\\modules\\transformers_modules\\chatglm-6b-int4\\modeling_ chatglm.py\", line 1280, in chat", "id": 129}
{"title": "[BUG] API deployment, streaming output function, missing a question", "file": "2023-05-24.0451", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/451", "detail": "**Problem / Problem."} Description**", "id": 130}
{"title": "Keep the project structure simple", "file": "2023-05-24.0454", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/454", "detail": "**Feature Description**", "id": 131}
{"title": "The project group can't scan the code to enter", "file": "2023-05-24.0455", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/455", "detail": "The project group can't scan the code to enter, can you add WeChat to pull me into the group, thank you!"} WeChat: daniel-0527", "ID": 132}
{"title": "Request to pull me into the group to discuss, Haishuo one, focus on LLM and other related technologies", "file": "2023-05-24.0461", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/461", "detail": "**Feature Description."} Description**", "id": 133}
{"title": "[BUG] chatglm-6b model error OSError: Error no file named pytorch_model.bin found in directory /chatGLM/model/model-6b", "file": "2023-05-26.0474", "url":  "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/474", "detail": "**1, Brief description: **", "id": 134}
{"title": "Now the QR code of this project exchange group cannot be scanned, and the group owner needs to pass", "file": "2023-05-27.0478", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/478", "detail": "Now the QR code of this project exchange group cannot be scanned, and the group owner needs to pass" , "id": 135}
{"title": "RuntimeError: Only Tensors of floating point and complex dtype can require gradients", "file": "2023-05-28.0483", "url": " https://github.com/imClumsyPanda/langchain-ChatGLM/issues/483", "detail": "Just updated with the latest version:", "id": 136}
{"title": "RuntimeError: \"LayerNormKernelImpl\" not implemented for 'Half'", "file": "2023-05-28.0484", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/484", "detail": "Solved params with only two arguments {'trust_remote_code': True, 'torch_dtype': torch.float16}", "id": 137}
{"title": "[BUG] File did not load successfully, please re-upload file", "file": "2023-05-31.0504", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/504", "detail": "webui.py", "id": 138}
{"title": "[BUG] bug 17 ,pdf and pdf why is it not the same?} Why are some PDFs recognized? Some PDFs can't be recognized? ", "file": "2023-05-31.0506", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/506", "detail": "bug 17 ,Why is pdf and pdf different? Why are some PDFs recognized? Some PDFs can't be recognized? ", "id": 139}
{"title": "[FEATURE] Concise description of the feature", "file": "2023-05-31.0513", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/513", "detail": "** Feature Description**", "id": 140}
{"title": "[BUG] webui.py Failed to load chatglm-6b-int4", "file": "2023-06-02.0524", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/524", "detail": "**Problem."} Description**", "id": 141}
{"title": "[BUG] webui.py Loading chatglm-6b model exception", "file": "2023-06-02.0525", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/525", "detail": "**Problem."} Description**", "id": 142}
{"title": "Add support for ChatGPT's Embedding and API calls", "file": "2023-06-02.0531", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/531", "detail": "Can OpenAI's Embedding be supported?"} API and conversational API? ", "id": 143}
{"title": "[FEATURE] Adjust the location of the model download", "file": "2023-06-02.0537", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/537", "detail": "The model is downloaded to $HOME/.cache/huggingface/ by default/ , when the C drive space is insufficient, the download of the model cannot be completed. There are also no parameters in configs/model_config.py to adjust the position of the model. ", "id": 144}
{"title": "[BUG] langchain=0.0.174 Error", "file": "2023-06-04.0543", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/543", "detail": "**Problem Description** ", "id": 145}
{"title": "[BUG] The path to load the local model is incorrect after update", "file": "2023-06-05.0545", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/545", "detail": "**Problem Description**", " id": 146}
{"title": "SystemError: 8-bit model requires CUDA support, or use a quantized model instead!"} , "file": "2023-06-06.0550", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/550", "detail": "After docker is deployed, start docker, and after a while, the container will automatically exit, and the logs error SystemError: The 8bit model requires CUDA Yes, or use a post-quantized model instead! [NVIDIA Container Toolkit] (https://github.com/NVIDIA/nvidia-container-toolkit) also installed", "id": 147}
{"title": "[BUG] Error message for uploading more than 1M KB", "file": "2023-06-06.0556", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/556", "detail": "**Problem Description**", "id" : 148}
{"title": "An error message is still reported after enabling AS access, and the request cannot be requested", "file": "2023-06-06.0560", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/560", "detail": "Error message:", "id": 149}
{"title": "dialogue_answering Is the code not used?} , I don't see the call", "file": "2023-06-07.0571", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/571", "detail": "what is dialogue_answering for", "id": 150}
{"title": "[BUG] The response time is extremely slow, where should I start to optimize?} 48C/128G/8 cards", "file": "2023-06-07.0573", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/573", "detail": "Operating environment: ubuntu20.04", "id": 151}
{"title": "An error is reported when running cli_demo in a CPU-only environment, indicating that the nvcuda.dll cannot be found", "file": "2023-06-08.0576", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/576", "detail": "The on-premises environment is CPU-only, The previous version works well in a CPU-only environment, but encode problems often occur when uploading a local knowledge base. After restarting the git project today, the following problem occurred during the runtime, how can I solve it? ", "id": 152}
{"title": "How to load a local embedding model(text2vec-large-Chinese model file)", "file": "2023-06-08.0582", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/582", "detail": " Because it needs to be deployed offline, so I want to put the model locally, I modified the HuggingFaceEmbeddings() in chains/local_doc_qa.py, and added a cache_folder parameter to it, so that the downloaded file is in the cache_folder, and the model_name is text2vec-large-Chinese. For example, cache_folder='/home/xx/model/text2vec-large-Chinese', model_name='text2vec-large-Chinese', you still need to download an online network to report an error, how can the boss solve this problem? ", "id": 153}
{"title": "ChatGLM-6B is installed on another server, how can I modify the interface of model.cofnig.py to use it?"}} , "file": "2023-06-09.0588", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/588", "detail": "I originally wanted to add an api base url here but running web.py found that it would still go to HuggingFace to download the model", "id": 154}
{"title": "[BUG] raise partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' when call interface `upload_file`", "file": "2023-06-10.0591", "url":  "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/591", "detail": "Problem Description", "id": 155}
{"title": "[BUG] raise OSError: [Errno 101] Network is unreachable when call interface upload_file and upload .pdf files", "file": "2023-06-10.0592", "url":  "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/592", "detail": "Problem Description", "id": 156}
{"title": "If you use Vicuna as the pedestal model, what do you need to modify?"} , "file": "2023-06-12.0596", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/596", "detail": "Is there a direct conversion of the Vikuna model? That is, the vicuna after the conversion of llama. ", "id": 157}
{"title": "[BUG] AttributeError: 'NoneType' object has no attribute 'get' error when calling api via cli.py", "file": "2023-06-12.0598", "url": " https://github.com/imClumsyPanda/langchain-ChatGLM/issues/598", "detail": "When calling the api via the 'python cli.py start api --ip localhost --port 8001' command, throw:", "id": 158}
{"title": "[BUG cli.py] 'langchain-ChatGLM: error: unrecognized arguments: start cli'", "file": "2023-06-12.0601", "url": " https://github.com/imClumsyPanda/langchain-ChatGLM/issues/601", "detail": "When starting a cli_demo with Python cli.py Start CLI, an error is reported:", "id": 159}
{"title": "[BUG] error: unrecognized arguments: --model-dir conf/models/", "file": "2023-06-12.0602", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/602", " detail": "Has the keyword parameter been modified? Is there any documentation? Big Guy", "id": 160}
{"title": "[BUG] Failed to upload all files", "file": "2023-06-12.0603", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/603", "detail": "ERROR: Exception in ASGI application", " id": 161}
{"title": "[BUG] config failed to start with chatyuan", "file": "2023-06-12.0604", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/604", "detail": "\"chatyuan\": {", "id": 162}
{"title": "After using the fashchat api, the background error APIError is as shown in the figure", "file": "2023-06-12.0606", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/606", "detail":  "I follow the https://github.com/imClumsyPanda/langchain-ChatGLM/blob/master/docs/fastchat.md", "id": 163}
{"title": "[BUG] Enable contextual association, each embedding will find more content than the previous one", "file": "2023-06-13.0613", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/613", "detail": "**Problem / Problem Description**", "id": 164}
{"title": "local_doc_qa.py MyFAISS.from_documents() is a statement that I don't understand. There is no such method in the MyFAISS class, and there are only from_texts methods in its parent FAISS and VectorStore[BUG] Concise description of the issue", "file": "2023-06-14.0619", "url": " https://github.com/imClumsyPanda/langchain-ChatGLM/issues/619", "detail": "local_doc_qa.py MyFAISS.from_documents() is not easy to understand. This method is not available in the MyFAISS class, and only from_texts method", "id": 165} in its parent class, FAISS and VectorStore.
{"title": "[BUG] TypeError: similarity_search_with_score_by_vector() got an unexpected keyword argument 'filter'", "file": "2023-06-14.0624", "url":  "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/624", "detail": "Problem Description", "id": 166}
{"title": "please delete this issue", "file": "2023-06-15.0633", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/633", "detail": "sorry, incorrect submission. Please remove this issue!", "id": 167}
{"title": "[BUG] vue front-end image build failed", "file": "2023-06-15.0635", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/635", "detail": "**Problem Description**", "id" : 168}
{"title": "Can the ChatGLM-6B model answer questions in English?"} , "file": "2023-06-15.0640", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/640", "detail": "Boss, may I ask, if the local knowledge document is in English, can the ChatGLM-6B model answer the English question?" If not, there is no alternative model recommendation, looking forward to your reply, thank you", "id": 169}
{"title": "[BUG] Concise description of the issue", "file": "2023-06-16.0644", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/644", "detail": "**Problem description / Problem Description**", "id": 170}
{"title": "KeyError: 3224", "file": "2023-06-16.0645", "url": "https://github.com/imClumsyPanda/langchain-ChatGLM/issues/645", "detail": "```", "id": 171}
